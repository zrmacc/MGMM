<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Zachary McCaw" />

<meta name="date" content="2019-01-17" />

<title>Gaussian Mixture Models with Missingness</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Gaussian Mixture Models with Missingness</h1>
<h4 class="author"><em>Zachary McCaw</em></h4>
<h4 class="date"><em>2019-01-17</em></h4>



<div id="contents" class="section level1">
<h1>Contents</h1>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#data-generation">Data Generation</a></li>
<li><a href="#parameter-estimation">Parameter Estimation</a></li>
</ul>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>Suppose that the data consist of independent random vectors. Each observation belongs to one of several distinct clusters. Conditional on cluster membership, the observation follows a multivariate normal distribution, with cluster-specific mean and covariance. The elements of an observation are subject to arbitrary patterns of missingness at random. That is, whether or not an element is missing is independent of that elementâ€™s value, given the observed elements. Given such data, this package estimates the cluster-specific means, covariances, and marginal membership probabilities. For each observation, the posterior probabiity of membership to each cluster is calculated, and a maximum a posteriori classification is provided.</p>
</div>
<div id="model" class="section level2">
<h2>Model</h2>
<p>Suppose that the data consist of <span class="math inline">\(n\)</span> random vectors <span class="math inline">\(y_{i}\)</span> in <span class="math inline">\(\mathbb{R}^{p}\)</span>. Each observation arises from one of <span class="math inline">\(k\)</span> clusters. Let <span class="math inline">\(z_{ij} = 1\)</span> if observation <span class="math inline">\(i\)</span> belongs to cluster <span class="math inline">\(j\)</span>. The marginal probability of membership the <span class="math inline">\(j\)</span>th cluster is <span class="math inline">\(\pi_{j} = P[z_{i}=j]\)</span>. Conditional on membership to the <span class="math inline">\(j\)</span>th cluster, <span class="math inline">\(z_{i}\)</span> follows a multivariate normal distribution with mean <span class="math inline">\(\mu_{j}\)</span> and covariance <span class="math inline">\(\Sigma_{j}\)</span>. The generative model is:</p>
<p><span class="math display">\[
z_{i} \sim \text{Multinomial}[\pi_{1},\cdots,\pi_{k}]
\]</span></p>
<p><span class="math display">\[
y_{i}\big|(z_{i}=j) \sim N\big(\mu_{j},\Sigma_{j}\big)
\]</span></p>
<p>The EM algorithm is used to obtain maximum likelihood estimates of the model parameters. Posterior probabilities of cluster membership are calculated as follows. Partition each observation <span class="math inline">\(y_{i}\)</span> as <span class="math inline">\((s_{i},\ t_{i})\)</span>, where <span class="math inline">\(s_{i}\)</span> denotes the observed elements, and <span class="math inline">\(t_{i}\)</span> denotes the missing elements. The posterior probability of membership to cluster <span class="math inline">\(j\)</span>, given the observed data <span class="math inline">\(s_{i}\)</span>, is:</p>
<p><span class="math display">\[
\gamma_{ij} = P[z_{i}=j|s_{i}] = \frac{f(s_{i}|\ \mu_{j},\Sigma_{j})\pi_{j}}{\sum_{l=1}^{k}f(s_{i}|\ \mu_{l},\Sigma_{l})\pi_{l}}
\]</span></p>
<p>The maximum a posteriori classificaiton for <span class="math inline">\(y_{i}\)</span> is:</p>
<p><span class="math display">\[
\arg\max_{j}\ \hat{\gamma}_{ij}
\]</span></p>
</div>
</div>
<div id="data-generation" class="section level1">
<h1>Data Generation</h1>
<div id="description" class="section level2">
<h2>Description</h2>
<p>The function <code>rMNMix</code> simulates observations from a Gaussian Mixture Model. The number of observations is specified by <code>n</code>, and the dimension of each observation by <code>d</code>. The number of clusters is set using <code>k</code>, which defaults to one. The marginal probabilities of cluster membership are provided as a numeric vector <code>pi</code>, which should contain <code>k</code> elements. If <span class="math inline">\(k&gt;0\)</span> but <code>pi</code> is omitted, the clusters are taken as equi-probable. The proportion of elements in the <span class="math inline">\(n \times d\)</span> data matrix that are missing is specified by <code>m</code>, which defaults to zero. Note that when <span class="math inline">\(m&gt;0\)</span> it is possible for all elements of an observation to go missing. The cluster means <code>M</code> are provided as a numeric prototype vector, or a list of such vectors. If a single prototype is provided, that vector is used as the mean for all clusters. By default, the zero vector is adopted as the prototype. The cluster covariances <code>S</code> are provided as a numeric matrix, or a list of such matrices. If a single prototype is provided, that matrix is used as the covariance for all clusters. By default, the identity matrix is adopted as the prototype.</p>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<div id="single-component-without-missingness" class="section level3">
<h3>Single Component without Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated from a single <code>k=1</code> bivariate normal distribution <code>d=2</code> without missingness. The mean is <span class="math inline">\(\mu=(2,2)\)</span>, and the covariance is an exchangeable correlation structure with off-diagonal <span class="math inline">\(\rho=0.5\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Single component without missingness</span>
Sigma =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">1</span>),<span class="dt">nrow=</span><span class="dv">2</span>);
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="fl">1e3</span>,<span class="dt">d=</span><span class="dv">2</span>,<span class="dt">k=</span><span class="dv">1</span>,<span class="dt">M=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">S=</span>Sigma);</code></pre></div>
</div>
<div id="single-component-with-missingness" class="section level3">
<h3>Single Component with Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated from a single <code>k=1</code> trivariate normal distribution <code>d=3</code> with 20% missingness <code>m=0.2</code>. The mean defaults to the zero vector, and the covariance to the identity matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Single component with missingness</span>
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="fl">1e3</span>,<span class="dt">d=</span><span class="dv">3</span>,<span class="dt">k=</span><span class="dv">1</span>,<span class="dt">m=</span><span class="fl">0.2</span>);</code></pre></div>
</div>
<div id="two-components-without-missingness" class="section level3">
<h3>Two Components without Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated from a two-coomponent <code>k=2</code> trivariate normal distribution <code>d=3</code> without missingness. The mean vectors are <span class="math inline">\(\mu_{1}=(-2,-2,-2)\)</span> and <span class="math inline">\(\mu_{2}=(2,2,2)\)</span>. The covariance matrices are both exchangeable with off-diagonal <span class="math inline">\(\rho=0.5\)</span>. Since <code>pi</code> is omitted, the cluster are equi-probable, i.e. <span class="math inline">\(\pi_{1}=\pi_{2}=1/2\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Two-component mixture without missingness</span>
M =<span class="st"> </span><span class="kw">list</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>),<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>));
Sigma =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">1</span>),<span class="dt">nrow=</span><span class="dv">3</span>);
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="fl">1e3</span>,<span class="dt">d=</span><span class="dv">3</span>,<span class="dt">k=</span><span class="dv">2</span>,<span class="dt">M=</span>M,<span class="dt">S=</span>Sigma);</code></pre></div>
</div>
<div id="four-components-with-missingness" class="section level3">
<h3>Four Components with Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated from a four-coomponent <code>k=4</code> bivariate normal distribution <code>d=2</code> with 10% missingness <code>m=0.1</code>. The mean vectors are <span class="math inline">\(\mu_{1}=(-2,-2)\)</span>, <span class="math inline">\(\mu_{2}=(-2,2)\)</span>, <span class="math inline">\(\mu_{3}=(2,-2)\)</span> and <span class="math inline">\(\mu_{4}=(2,2)\)</span>. The covariance matrices are all <span class="math inline">\(0.5*I\)</span>. The cluster proportions are (35%, 15%, 15%, 35%) for <span class="math inline">\((\pi_{1},\pi_{2},\pi_{3},\pi_{4})\)</span>, respectively.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Four-component mixture with missingness</span>
M =<span class="st"> </span><span class="kw">list</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>),<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>),<span class="kw">c</span>(<span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>),<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>));
S =<span class="st"> </span><span class="fl">0.5</span><span class="op">*</span><span class="kw">diag</span>(<span class="dv">2</span>);
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="fl">1e3</span>,<span class="dt">d=</span><span class="dv">2</span>,<span class="dt">k=</span><span class="dv">4</span>,<span class="dt">pi=</span><span class="kw">c</span>(<span class="fl">0.35</span>,<span class="fl">0.15</span>,<span class="fl">0.15</span>,<span class="fl">0.35</span>),<span class="dt">m=</span><span class="fl">0.1</span>,<span class="dt">M=</span>M,<span class="dt">S=</span>S);</code></pre></div>
</div>
</div>
</div>
<div id="parameter-estimation" class="section level1">
<h1>Parameter Estimation</h1>
<div id="description-1" class="section level2">
<h2>Description</h2>
<p>The function <code>fit.MNMix</code> estimates parameters for the Gaussian Mixture Model. The data are expected as a numeric matrix <code>Y</code>, with observations as rows. The number of mixture components is specified using <code>k</code>, which defaults to one. Initial values for the mean vectors, covariance matrices, and cluster proportions are provided using <code>M0</code>, <code>S0</code>, and <code>pi0</code>, respectively. If the data <code>Y</code> contain complete observations, i.e.Â observations with no missing elements, <code>fit.MNMix</code> will attempt to initialize the model parameters (<span class="math inline">\(\mu,\Sigma,\pi\)</span>) via K-means. However, if the data <code>Y</code> contain no complete observations, then initial values are required for each of <code>M0</code>, <code>S0</code>, and <code>pi0</code>. Supplying initial values may also result in more accurate estimates when there are relatively few complete observations. The initial means <code>M0</code> are provided as a list of vectors, the covariances <code>S0</code> as a list of matrices, and the cluster proportions <code>pi0</code> as a numeric vector. Note that <code>M0</code> and <code>S0</code> are expected as lists even if the model only contains a single component <code>k=1</code>.</p>
<p>The arguments <code>maxit</code>, <code>eps</code>, <code>report</code>, and <code>parallel</code> control the fitting procedure. <code>maxit</code> sets the maximum number of EM iterations to attempt. The default is <span class="math inline">\(10^{2}\)</span>. <code>eps</code> sets the minimum acceptable improvement in the EM objective function. The default is <span class="math inline">\(10^{-6}\)</span>. If <code>report=TRUE</code>, then fitting progress is displayed. For models with missingness and more than one mixture component <code>k&gt;1</code>, setting <code>parallel=TRUE</code> may improve run time. The parallel backend must be registered beforehand.</p>
</div>
<div id="examples-1" class="section level2">
<h2>Examples</h2>
<div id="single-component-without-missingness-1" class="section level3">
<h3>Single Component without Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated with a single bivariate normal distribution without missingness. Since the model contains only a single component, the output is a list containing the estimated mean and covariance. In the case of a single component without missingness, the maximum likelihood estimates are available in closed form.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Single component without missingness</span>
Sigma =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">1</span>),<span class="dt">nrow=</span><span class="dv">2</span>);
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="fl">1e3</span>,<span class="dt">d=</span><span class="dv">2</span>,<span class="dt">k=</span><span class="dv">1</span>,<span class="dt">M=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">S=</span>Sigma);
M =<span class="st"> </span><span class="kw">fit.MNMix</span>(<span class="dt">Y=</span>Y,<span class="dt">k=</span><span class="dv">1</span>);
<span class="kw">cat</span>(<span class="st">&quot;Estimated Mean and Covariance:</span><span class="ch">\n</span><span class="st">&quot;</span>);
<span class="kw">show</span>(M);</code></pre></div>
<pre><code>## Estimated Mean and Covariance:
## $Mean
##       y1       y2 
## 1.996801 2.011534 
## 
## $Covariance
##           y1        y2
## y1 1.0539240 0.5306348
## y2 0.5306348 1.0085668
## 
## $Objective
## [1] -1751.402</code></pre>
</div>
<div id="single-component-with-missingness-1" class="section level3">
<h3>Single Component with Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated from a single trivariate normal distribution with 20% missingness. Since the model contains only a single component, the output is again a list. However, in the case of missingness, the EM algorithm is used for estimation. In addition to the estimated mean and covariance, the output now contains the final EM objective. The true mean is the zero vector, and the true covariance is identity. For <code>M1</code> below, the initial mean and covariance are estimated internally using complete observations. For <code>M2</code> below, the mean and covariance are initialized at the truth. The final value of the EM objective is increased by initializing at the truth.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Single component with missingness</span>
<span class="kw">set.seed</span>(<span class="dv">100</span>);
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="fl">1e3</span>,<span class="dt">d=</span><span class="dv">3</span>,<span class="dt">k=</span><span class="dv">1</span>,<span class="dt">m=</span><span class="fl">0.2</span>);
<span class="kw">cat</span>(<span class="st">&quot;Initial parameter values set internally:</span><span class="ch">\n</span><span class="st">&quot;</span>);
M1 =<span class="st"> </span><span class="kw">fit.MNMix</span>(<span class="dt">Y=</span>Y,<span class="dt">k=</span><span class="dv">1</span>);
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>);
<span class="kw">show</span>(M1);
<span class="kw">cat</span>(<span class="st">&quot;Initial parameter values set manually:</span><span class="ch">\n</span><span class="st">&quot;</span>);
m0 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">3</span>);
S0 =<span class="st"> </span><span class="kw">diag</span>(<span class="dv">3</span>);
M2 =<span class="st"> </span><span class="kw">fit.MNMix</span>(<span class="dt">Y=</span>Y,<span class="dt">k=</span><span class="dv">1</span>,<span class="dt">M0=</span><span class="kw">list</span>(m0),<span class="dt">S0=</span><span class="kw">list</span>(S0));
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>);
<span class="kw">show</span>(M2);
<span class="kw">cat</span>(<span class="st">&quot;Gain in final objective by initializing parameters at the truth:</span><span class="ch">\n</span><span class="st">&quot;</span>)
M2<span class="op">$</span>Objective<span class="op">-</span>M1<span class="op">$</span>Objective;</code></pre></div>
<pre><code>## Initial parameter values set internally:
## Objective increment:  5.81 
## Objective increment:  0.662 
## Objective increment:  0.0976 
## Objective increment:  0.0143 
## Objective increment:  0.00147 
## 5 update(s) performed before tolerance limit.
## 
## 
## $Mean
##          y1          y2          y3 
##  0.05363057 -0.03032985  0.02118261 
## 
## $Covariance
##              y1            y2            y3
## y1  0.995409482 -0.0272300548  0.0084440124
## y2 -0.027230055  1.0377546994 -0.0008892942
## y3  0.008444012 -0.0008892942  1.0590200651
## 
## $Objective
## [1] -3064.304
## 
## Initial parameter values set manually:
## 0 update(s) performed before tolerance limit.
## 
## 
## $Mean
## [1] 0 0 0
## 
## $Covariance
##      [,1] [,2] [,3]
## [1,]    1    0    0
## [2,]    0    1    0
## [3,]    0    0    1
## 
## $Objective
## NULL
## 
## Gain in final objective by initializing parameters at the truth:
## numeric(0)</code></pre>
</div>
<div id="two-components-without-missingness-1" class="section level3">
<h3>Two Components without Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated from a two-component trivariate normal distribution without missingness. Since the model has multiple components, the output is an object of class <code>mix</code>. The show method displays the estimated cluster proportions and the final objective. The slots <code>@Means</code> and <code>@Covariances</code> contain lists of the estimated cluster means and covariances. The posterior probability of membership to each cluster is contained in the <code>@Responsibilities</code> slot, and the highest posterior probability classification of each observation is contained in the <code>@Assignments</code> slot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Two componets without missingness</span>
Means =<span class="st"> </span><span class="kw">list</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>),<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>));
Sigma =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">1</span>),<span class="dt">nrow=</span><span class="dv">3</span>);
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="fl">1e3</span>,<span class="dt">d=</span><span class="dv">3</span>,<span class="dt">k=</span><span class="dv">2</span>,<span class="dt">M=</span>Means,<span class="dt">S=</span>Sigma);
M =<span class="st"> </span><span class="kw">fit.MNMix</span>(<span class="dt">Y=</span>Y,<span class="dt">k=</span><span class="dv">2</span>,<span class="dt">eps=</span><span class="fl">1e-8</span>);
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>);
<span class="kw">show</span>(M);
<span class="kw">cat</span>(<span class="st">&quot;Cluster means:</span><span class="ch">\n</span><span class="st">&quot;</span>);
M<span class="op">@</span>Means;
<span class="kw">cat</span>(<span class="st">&quot;Cluster covariances:</span><span class="ch">\n</span><span class="st">&quot;</span>);
M<span class="op">@</span>Covariances;
<span class="kw">cat</span>(<span class="st">&quot;Cluster responsibilities:</span><span class="ch">\n</span><span class="st">&quot;</span>);
<span class="kw">head</span>(M<span class="op">@</span>Responsibilities);
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Cluster assignments:</span><span class="ch">\n</span><span class="st">&quot;</span>);
<span class="kw">head</span>(M<span class="op">@</span>Assignments);</code></pre></div>
<pre><code>## Objective increment:  0.396 
## Objective increment:  0.034 
## Objective increment:  0.00965 
## Objective increment:  0.00282 
## Objective increment:  0.000957 
## Objective increment:  0.000395 
## Objective increment:  0.000189 
## Objective increment:  9.75e-05 
## Objective increment:  5.22e-05 
## Objective increment:  2.83e-05 
## Objective increment:  1.54e-05 
## Objective increment:  8.43e-06 
## Objective increment:  4.61e-06 
## Objective increment:  2.52e-06 
## Objective increment:  1.38e-06 
## Objective increment:  7.56e-07 
## Objective increment:  4.14e-07 
## Objective increment:  2.27e-07 
## Objective increment:  1.24e-07 
## Objective increment:  6.79e-08 
## Objective increment:  3.72e-08 
## Objective increment:  2.03e-08 
## Objective increment:  1.11e-08 
## Objective increment:  6.1e-09 
## 23 update(s) performed before tolerance limit.
## 
## 
## Normal Mixture Model with 2 Components. 
## Cluster Proportions:
##    k1    k2 
## 0.518 0.482 
## 
## Final Objective:
##      k1 
## -2982.3 
## 
## Cluster means:
## [[1]]
##        y1        y2        y3 
## -1.949991 -1.912998 -1.982099 
## 
## [[2]]
##       y1       y2       y3 
## 1.964810 1.933682 1.956676 
## 
## Cluster covariances:
## [[1]]
##           y1        y2        y3
## y1 0.9347688 0.5095796 0.4896254
## y2 0.5095796 1.0477300 0.4895118
## y3 0.4896254 0.4895118 0.9365137
## 
## [[2]]
##          y1        y2        y3
## y1 1.070444 0.5310510 0.5222580
## y2 0.531051 1.0483091 0.5286882
## y3 0.522258 0.5286882 1.0013230
## 
## Cluster responsibilities:
##             k1           k2
## 1 9.997767e-01 2.232718e-04
## 2 1.693337e-03 9.983067e-01
## 3 9.999994e-01 6.164588e-07
## 4 9.910511e-01 8.948881e-03
## 5 3.285010e-05 9.999671e-01
## 6 4.350046e-08 1.000000e+00
## 
## Cluster assignments:
##   Assignment
## 1          1
## 2          2
## 3          1
## 4          1
## 5          2
## 6          2</code></pre>
</div>
<div id="four-components-with-missingness-1" class="section level3">
<h3>Four Components with Missingness</h3>
<p>In this example, <span class="math inline">\(10^{3}\)</span> observations are simulated from a four-component bivariate normal distribution with 10% missingness. Since the model has multiple components, the output is an object of class <code>mix</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">200</span>);
<span class="co"># Four components with missingness</span>
M =<span class="st"> </span><span class="kw">list</span>(<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>),<span class="kw">c</span>(<span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>),<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>),<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>));
S =<span class="st"> </span><span class="fl">0.5</span><span class="op">*</span><span class="kw">diag</span>(<span class="dv">2</span>);
Y =<span class="st"> </span><span class="kw">rMNMix</span>(<span class="dt">n=</span><span class="dv">1000</span>,<span class="dt">d=</span><span class="dv">2</span>,<span class="dt">k=</span><span class="dv">4</span>,<span class="dt">pi=</span><span class="kw">c</span>(<span class="fl">0.35</span>,<span class="fl">0.15</span>,<span class="fl">0.15</span>,<span class="fl">0.35</span>),<span class="dt">m=</span><span class="fl">0.1</span>,<span class="dt">M=</span>M,<span class="dt">S=</span>S);
M =<span class="st"> </span><span class="kw">fit.MNMix</span>(<span class="dt">Y=</span>Y,<span class="dt">k=</span><span class="dv">4</span>,<span class="dt">eps=</span><span class="fl">1e-8</span>);
<span class="kw">show</span>(M);
<span class="kw">cat</span>(<span class="st">&quot;Cluster means:</span><span class="ch">\n</span><span class="st">&quot;</span>);
M<span class="op">@</span>Means;
<span class="kw">cat</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Cluster assignments:</span><span class="ch">\n</span><span class="st">&quot;</span>);
<span class="kw">head</span>(M<span class="op">@</span>Assignments);</code></pre></div>
<pre><code>## Objective increment:  6980 
## Objective increment:  168 
## Objective increment:  90.9 
## Objective increment:  57.4 
## Objective increment:  36.8 
## Objective increment:  26.9 
## Objective increment:  20.6 
## Objective increment:  17.1 
## Objective increment:  15.1 
## Objective increment:  14.1 
## Objective increment:  14.1 
## Objective increment:  14.3 
## Objective increment:  15.1 
## Objective increment:  15.4 
## Objective increment:  15 
## Objective increment:  13.2 
## Objective increment:  10.7 
## Objective increment:  7.68 
## Objective increment:  5.26 
## Objective increment:  3.31 
## Objective increment:  2.02 
## Objective increment:  1.12 
## Objective increment:  0.574 
## Objective increment:  0.207 
## 24 update(s) performed before tolerance limit.
## 
## Normal Mixture Model with 4 Components. 
## Cluster Proportions:
##     k1     k2     k3     k4 
## 0.0863 0.3220 0.2190 0.3730 
## 
## Final Objective:
##       k1 
## -2649.01 
## 
## Cluster means:
## [[1]]
##         y1         y2 
## -0.9088869  0.4385624 
## 
## [[2]]
##       y1       y2 
## 1.994131 1.992714 
## 
## [[3]]
##          y1          y2 
##  0.03938591 -0.03059968 
## 
## [[4]]
##        y1        y2 
## -2.038837 -2.006364 
## 
## 
## Cluster assignments:
##   Assignment
## 1          2
## 2          3
## 3          4
## 4          4
## 5          2
## 6          2</code></pre>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
